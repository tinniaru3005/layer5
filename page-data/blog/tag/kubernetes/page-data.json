{"componentChunkName":"component---src-templates-blog-tag-list-js","path":"/blog/tag/kubernetes","result":{"data":{"allMdx":{"totalCount":4,"nodes":[{"id":"6a0f849a-8fcf-586a-9cf3-0beaac085455","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Kubernetes 1.26 Highlights, Features, and Deprecations\",\n  \"subtitle\": null,\n  \"date\": \"2022-12-06 08:00:00 -0530\",\n  \"author\": \"Lee Calcote\",\n  \"thumbnail\": \"./kubernetes-new.png\",\n  \"darkthumbnail\": \"./kubernetes-new-dark.png\",\n  \"description\": \"Release Notes: What changed in Kubernetes 1.26?\",\n  \"type\": \"Blog\",\n  \"category\": \"Kubernetes\",\n  \"tags\": [\"Kubernetes\"],\n  \"featured\": false,\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(BlogWrapper, {\n    mdxType: \"BlogWrapper\"\n  }, mdx(\"p\", null, \"As the final Kubernetes release of 2022, Kubernetes 1.26 is an exciting new release of the popular container orchestration platform. It offers a number of new features and improvements that will help platform engineers and DevOps engineers manage their Kubernetes clusters more effectively. Here are some of the highlights of this release.\"), mdx(\"div\", {\n    className: \"intro\"\n  }, mdx(\"p\", null, \"As a longstanding CNCF member, Layer5 has donated two of its open source projects to the CNCF: \", mdx(Link, {\n    to: \"/cloud-native-management/meshery\",\n    mdxType: \"Link\"\n  }, \"Meshery\"), \" and \", mdx(Link, {\n    to: \"/projects/service-mesh-performance\",\n    mdxType: \"Link\"\n  }, \"Service Mesh Performance\"), \". As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you.\")), mdx(\"p\", null, \"While there are a number of enhancments tracked in this release (38), you need to be aware that there are also a number of features being deprecated (10) in 1.26. In this article, we will focus on some highlighted enhancements, important deprecations, and removals so that you can be confident before upgrading your clusters. \"), mdx(\"p\", null, \"We'll breakdown new K8s features by category, starting with networking.\"), mdx(\"h2\", null, \"Networking in Kubernetes 1.26\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/2086\"\n  }, \"Service Internal Traffic Policy\"), \" \", \"[Stable]\"), mdx(\"p\", null, \"When requests are made to a Kubernetes service, they are randomly distributed to all available endpoints. The new enhancement enriches the API of a service to use node-local and topology-aware routing for internal traffic. The new internalTrafficPolicy field has two options: Cluster (default) and Local. The Cluster option works like before and tries distributing requests to all available endpoints. On the other hand, the Local option only sends requests to node-local endpoints and drops the request if there is no available instance on the same node. The Local option is useful for sending metrics or logs to an agent running as a DaemonSet. \"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/3070\"\n  }, \"Reserve Service IP Ranges for Dynamic and Static IP Allocation\"), \" \", \"[Stable]\"), mdx(\"p\", null, \"Kubernetes services are assigned a virtual ClusterIP to be reachable inside the cluster. The ClusterIP is either assigned dynamically from a configured Service IP range, or statically set while creating the service resource. There was no possibility of knowing whether another service in the cluster had already used the static ClusterIP before this new stable enhancement. With this change, the IP range is divided into two; this prevents conflicts between services implementing dynamic IP allocation and static IP assignment. The flag --service-cluster-ip-range, with CIDR notation, is part of the Kubernetes API server configuration and is ready to use with the 1.26 release. \"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/1435\"\n  }, \"Support of Mixed Protocols in Services with Type LoadBalancer\"), \" \", \"[Stable]\"), mdx(\"p\", null, \"Kubernetes Services that use the LoadBalancer type have only supported a single Layer 4 protocol until now. With this enhancement going from graduating to stable in v1.26, it is possible to define a mix of protocols in the same service definition. In other words, this enhancement allows a LoadBalancer Service to serve different protocols (e.g. UDP, TCP) under the same port (e.g. 443). For example, serving both UDP and TCP requests for a DNS or SIP server on the same port. For instance, you can expose a DNS server with a single load balancer IP for both TCP and UDP requests, such as the following:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-yaml\"\n  }, \"apiVersion: v1\\nkind: Service\\nmetadata:\\n  name: multi-protocol-dns-server\\nspec:\\n  type: LoadBalancer\\n  ports:\\n    - name: dns-udp\\n      port: 53\\n      protocol: UDP\\n    - name: dns-tcp\\n      port: 53\\n      protocol: TCP\\n  selector:\\n    app: dns-server\\n\")), mdx(\"h2\", null, \"Security in Kubernetes 1.26\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/2133\"\n  }, \"kubelet Credential Provider\"), \" \", \"[Stable]\"), mdx(\"p\", null, \"The kubelet agent has a built-in credential provider mechanism to retrieve credentials for container image registries. It natively supports Azure, Google Cloud, and AWS container image registries for dynamically retrieving their credentials. The new stable enhancement in v1.26 offers a replacement for the in-tree implementations, and creates an API for extensible plugins in the future. \"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/3031\"\n  }, \"SignedSigning Release Artifacts\"), \" \", \"[Beta]\"), mdx(\"p\", null, \"Every Kubernetes release produces a set of artifacts such as binaries, container images, documentation, and metadata. Since the 1.24 release, the artifacts have been signed as an alpha feature. In the 1.26 release, artifact signing graduates to beta to increase software supply chain security for the Kubernetes release process and mitigate man-in-the-middle attacks.\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/2799\"\n  }, \"Reduction of Secret-Based Service Account Tokens\"), \" \", \"[Beta]\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"BoundServiceAccountTokenVolume\"), \" has been GA since version 1.22: Service account tokens for pods are obtained via the TokenRequest API and stored as a projected volume. The new enhancement, in beta, eliminates the need to auto-generate secret-based service account tokens. In addition, Kubernetes will warn about using auto-created secret-based service account tokens, and purge the unused ones.\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/1981\"\n  }, \"Windows Privileged Containers\"), \" \", \"[Stable]\", \" and \", mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/3503\"\n  }, \"Host Networking\"), \" \", \"[Alpha]\"), mdx(\"p\", null, \"Privileged containers are the ones that have similar access and capabilities to the host processes running on the servers. In Linux environments, they are used heavily in Kubernetes for storage, networking, and management. In this release, support for privileged containers for the Windows environment graduates to stable. Management of processes is heavily different from the operating system standpoint in Linux and Windows. Therefore, privileged containers will also work differently in two environments, but they will ensure the same level of security and operational experience.\"), mdx(\"p\", null, \"In addition, there is a new alpha-level enhancement in this release to support host networking for Windows pods. Currently, Windows has all the functionality to make containers use the networking namespace of the nodes. The new alpha enhancement enables this functionality from the Kubernetes side, increasing the parity between Linux and Windows containers.\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/33250\"\n  }, \"Self-User Attribute and Authentication API\"), \" \", \"[Alpha]\"), mdx(\"p\", null, \"Kubernetes has no resources to identify and manage users as part of its API. Instead, it uses authenticators to get user attributes from tokens, certificates, OIDC providers, or webhooks. The new alpha feature adds a new API endpoint to see what attributes the current users have. The new API is under authentication.k8s.io with the name SelfSubjectReview, and there is a new corresponding command as well: kubectl auth who-am-i. The new feature will reduce the obscurity of complex authentication and help users debug the authentication stack. \"), mdx(\"h2\", null, \"Scheduling in Kubernetes 1.26\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/2268\"\n  }, \"Non-Graceful Node Shutdown for StatefulSet Pods\"), \" \", \"[Beta]\"), mdx(\"p\", null, \"As a platform Kubernetes is hardened and has been deploy by thousands and thousands of users. Hardening of Kubernetes makes itself resistant to disasters. The kubelet agent that runs on each node in a Kubernetes cluster already uses graceful node shutdown to detect and offboard workloads to other nodes. However, when the shutdown is not detected by the kubelet, the pods of a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StatefulSet\"), \" are stuck as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Terminating\"), \" and not transferred to a healthy node. The kubelet on the downed node will not delete its pods from Kubernetes API, and the StatefulSet controller will not create new pods with the same name. This happens due to a conflict in the Kubernetes machinery. With this enhancement moving into beta, though, pods will be forcefully deleted along with their volume attachments and new pods will be migrated (created) on healthy nodes.\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/3521\"\n  }, \"Pod Scheduling Readiness\"), \" \", \"[Alpha]\"), mdx(\"p\", null, \"Currently, pods are considered ready for scheduling as soon as they are created. However, not every pod requires a node, resource allocation, and the start of all its containers immediately after its creation. The new alpha enhancement adds an API to mark pods with their scheduling status: paused and ready. Pods with the .spec.schedulingGates field will be parked in the scheduler and only be assigned to nodes when they are ready to be scheduled.\"), mdx(\"h3\", null, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"https://github.com/kubernetes/enhancements/issues/3515\"\n  }, \"kubectl explain to use OpenAPI v3 for \"), \" \", \"[Alpha]\"), mdx(\"p\", null, \"Use of OpenAPI v3 means supporting rich type information in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl explan\"), \". Kubernetes has supported OpenAPI v3 as a beta since version 1.24. This richer representation of the fields in the Kubernetes API, means that users can use the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl explain\"), \" command to get information that is only detailed in  OpenAPI v3, and not the subset defined OpenAPI v2.\"), mdx(\"h2\", null, \"Deprecations and Removals\"), mdx(\"p\", null, \"Consistent to the Kubernetes API lifecycle is deprecations and removals of APIs in each release. It is strongly suggested to check whether you are using the following APIs and flags before there are breaking changes.\"), mdx(\"ul\", null, mdx(\"li\", null, \"Removal of the `flowcontrol.apiserver.k8s.io/v1beta1` API group for `FlowSchema` and `PriorityLevelConfiguration` requires a migration to the v1beta2 API version.\"), mdx(\"li\", null, \"Removal of the `autoscaling/v2beta2` API version for HorizontalPodAutoscaler requires a migration to the autoscaling/v2 API version.\"), mdx(\"li\", null, \"Removal of legacy and vendor-specific authentication client-go and kubectl for Azure and Google Cloud requires migration to vendor-neutral authentication plugin mechanisms.\"), mdx(\"li\", null, \"Removal of in-tree CSI integration for OpenStack\\u2014namely, the `cinder` volume type\\u2014requires a migration to use the CSI driver for OpenStack.\"), mdx(\"li\", null, \"Some unused options and flags for the kubectl run command are marked as deprecated in the 1.26 release, such as `--grace-period`, `--timeout`, and `--wait`.\")), mdx(\"h2\", null, \"Last Kubernetes release of 2022\"), mdx(\"p\", null, \"Kubernetes is an ever-evolving platform. For those of you running workloads on Kubernetes taking detailed note of API changes and enhancements is an important activity as you endevour to keep your clusters upgraded with release releases. A more secure, scalable, and flexible Kubernetes is our collective goal. Dign into more details about deprecation, removals, and the latest changes in the 1.26 \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://relnotes.k8s.io/\"\n  }, \"release notes\"), \".\"), mdx(\"p\", null, \"On behalf of the Layer5 community and all of the CNCF projects that its contributors steward, thank you to everyone who participated in this Kubernetes release, and congratulations! \"), mdx(\"p\", null, \"As an end-to-end, open-source, multi-cluster Kuberentes management platform, Meshery makes Day 2 Kubernetes cluster management a breeze. Run Meshery to explore the behavorial changes of this Kubernetes release and what they really mean to you. \")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Kubernetes 1.26 Highlights, Features, and Deprecations","subtitle":null,"date":"December 6th, 2022","author":"Lee Calcote","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAACl0lEQVQ4y72U+0uTURjHhf6A+kGQ/KEfwgIpkSBaVJIKFYRBkYWZhZpdsEjJoBAS0gWJ0QUrA4nM1GCWJo4aZsOWWoGt2zShMHfR4dzcpTY333PON97r9jZLAunAw3PO87zn837Pcy4JWJzGZJ/wX4CMMcVTykAoU8Xk/oLA2ElEAsXmCPkjOB4oJ6mkSm7D1ggGR2bVYBoHVQNj/xoLqmyagaZsAumlDhy5Ng3jh5CSp1Q1Jx5IJZjTw6HsjhtrjjuQuN+KPdVTOHp9Gkl5VqQU2ZGrncLb0bAKOu+SOSLGrnb4BNjhOhdKb7rRYw7h9ZcwLjTP4GCtCxlnJ5Ff61LKs6DCU7fdSCm2Q2f6Cct4BDVtXjQ+C6BzQBxvLJ9A9jkn3H6iQOOAMiwQpNhW6cTqEjsa9H7UtfsEyKh9DncNASG2vdKJlYU2mL+JyyaE8oKYJEwEyrvGf5R2wiHUbOhrGM29AQx/n4VlLIRHL/14MxJEnc6D1BIrGrq9okJl81lUoQw0fZ4VgLurp9Bm9KNeH0TrIPDUAlzWA7ohoKA+jNTTPtwwiKiQxw3KcWqFsTXUPvQi+cA40ss9MPY7oG/pxZUqHcYe34e2oArHNhSiZtNOGHLWo29HCgyaRLgGnotAQqK7LANBCYpvBZG1rxu6zHSMVOzF++Kt6M1aAVN2MgYylqE/KwmmXWvRs2W5YHM//JJCqj7YfIH55rB50LRqKYzrluDjpTMwny/Cu4p8vMrbjL5cDYw5afh08SQGD2XC2t4oICjHzXP1+HPFDyIhuF50wNbVAlvHPdifNMPW2QR71wPBHN2tgp80tIMRTtkUpYZiJNph//p2/XZsmGxSQvB8gRnhJP8Xi85Z1AcWsTeFLab9AshDtKwT8lG6AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/cb5e88af4075e63b16a33b56b3659b9a/db189/kubernetes-new.png","srcSet":"/static/cb5e88af4075e63b16a33b56b3659b9a/f054e/kubernetes-new.png 750w,\n/static/cb5e88af4075e63b16a33b56b3659b9a/db189/kubernetes-new.png 900w","sizes":"100vw"},"sources":[{"srcSet":"/static/cb5e88af4075e63b16a33b56b3659b9a/4f03f/kubernetes-new.webp 750w,\n/static/cb5e88af4075e63b16a33b56b3659b9a/3987a/kubernetes-new.webp 900w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}},"extension":"png","publicURL":"/static/cb5e88af4075e63b16a33b56b3659b9a/kubernetes-new.png"}},"fields":{"slug":"/blog/kubernetes/kubernetes-126-highlights-features-and-deprecations"}},{"id":"ee4ff46e-ae65-555e-835d-ca9902fd8876","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Structured logging in Kubernetes with Klog\",\n  \"subtitle\": \"Deprecating Klog flags in Kubernetes 1.26\",\n  \"date\": \"2022-12-05 15:00:00 -0530\",\n  \"author\": \"Lee Calcote\",\n  \"thumbnail\": \"./kubernetes-logs.png\",\n  \"darkthumbnail\": \"./kubernetes-logs-dark.png\",\n  \"description\": \"Structured logging in Kubernetes 1.26 with Klog\",\n  \"type\": \"Blog\",\n  \"category\": \"Kubernetes\",\n  \"tags\": [\"Kubernetes\", \"OpenTelemetry\"],\n  \"featured\": false,\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(BlogWrapper, {\n    mdxType: \"BlogWrapper\"\n  }, mdx(\"p\", null, \"As a platform for developers and system administrators to easily deploy and manage applications in a distributed environment, Kubernetes clusters generate logs and lots of them. One of the key components of Kubernetes is its logging and instrumentation capabilities. The upcoming Kubernetes 1.26 release has a handful of noteworthy changes to its system component logger, \", mdx(\"code\", null, \"klog\"), \".\"), mdx(\"h2\", null, \"Kubernetes System Log\"), mdx(\"p\", null, \"System component logs record events happening in K8s clusters. More than metrics or traces, logs are the telemetric signal often found to be most useful for debugging. You can configure K8s log verbosity to see more or less detail. Logs can be as coarse-grained as showing errors within a component, or as fine-grained as showing step-by-step traces of events (like HTTP access logs, pod state changes, controller actions, or scheduler decisions).\"), mdx(\"h2\", null, \"Klog\"), mdx(\"p\", null, mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/kubernetes/klog\"\n  }, \"klog\"), \" is a Kubernetes logging library that provides an API for developers and system administrators to instrument their applications for logging and tracing. klog generates log messages for the Kubernetes system components. It provides a comprehensive set of features, including log levels, structured logging and logging context.\"), mdx(\"p\", null, \"Kubernetes 1.23 introduced structured logging (in beta) in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"klog\"), \". Structured logging is a uniform structure in log messages allowing for programmatic extraction of information. Structured logs can be stored and processed with less effort and cost. The code which generates a log message determines whether it uses the traditional unstructured \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"klog\"), \" output or structured logging.\"), mdx(\"p\", null, \"As a dependency to structured logging (gated behind \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"StructuredLogging\"), \" feature gate), Kubernetes 1.24 introducted contextual logging (in alpha) in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"klog\"), \". Contextual logging builds on top of structured logging. It is primarily about how developers use logging calls: code based on that concept is more flexible and supports additional use cases which will be the topic of a future blog post. \"), mdx(\"h3\", null, \"Klog Deprecations in Kubernetes 1.26\"), mdx(\"p\", null, \"Kubernetes has recently announced that it intends to deprecate certain flags related to Klog in its components. This means that Klog-specific flags, such as \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--klog-verbosity\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--klog-vmodule\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"--klog-stderrthreshold\"), \" will no longer be supported. This is due to the fact that Klog has been largely superseded by the more comprehensive OpenTelemetry project, which provides a more complete solution for logging and instrumentation.\"), mdx(\"p\", null, \"The deprecation of Klog-specific flags is a positive step forward for Kubernetes as it moves to OpenTelemetry. This move will ensure that Kubernetes is using the industry-standard logging and instrumentation solution. It will also provide developers and system administrators with a more comprehensive, reliable and consistent experience when instrumenting their applications.\\nA goal of this deprecation is one of unblocking development of alternative logging formats. Why does Kubnernetes need another logging format? One reason is performance. Klog performance is much worse than alternatives, for example 7-8x than JSON format:\"), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"logger\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"time \", \"[ns/op]\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"bytes\", \"[B/op]\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"allocations\", \"[alloc/op]\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"Text Infof\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"2252\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"248\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"3\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"Text InfoS\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"2455\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"280\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"3\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"JSON Infof\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"1406\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"19\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"1\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"JSON InfoS\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"319\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"67\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": null\n  }, \"1\")))), mdx(\"p\", null, \"Proof of concept implementation of new logging formats were completed to assess the potentional gains of using an alternative format. Results measured on 30s benchmark for passing 2 arguments to format function.\"), mdx(\"div\", {\n    className: \"tip\"\n  }, mdx(\"h3\", null, \"Tip: Logger Performance Comparison\"), mdx(\"p\", null, \"Interestingly, Klog isn't the fastest logger in the West, but Uber's open source project \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/uber-go/zap\"\n  }, \"zap \"), \" appears to hold that title instead. The following performance test benchmark is an examle of one of a number of scenarios in which loggers can be performance analyzed.\"), mdx(\"p\", null, \"Log a message and 10 fields:\"), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"Package\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Time\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Time % to zap\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Objects Allocated\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"zap\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"2900 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+0%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"5 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"zap (sugared)\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"3475 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+20%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"10 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"zerolog\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"10639 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+267%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"32 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"go-kit\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"14434 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+398%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"59 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"logrus\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"17104 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+490%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"81 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"apex/log\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"32424 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+1018%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"66 allocs/op\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"left\"\n  }, \"log15\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"33579 ns/op\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"+1058%\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"76 allocs/op\"))))), mdx(\"p\", null, \"Output will always be written to stderr, regardless of the output format. Output redirection is expected to be handled by the component which invokes a Kubernetes component. This can be a POSIX shell or a tool like systemd.\"), mdx(\"p\", null, \"The deprecation of Klog-specific flags is part of a larger effort to transition Kubernetes to a more modern and comprehensive logging and instrumentation solution. This will provide Kubernetes users with a more reliable, secure and consistent experience when instrumenting and monitoring their applications.\"), mdx(\"p\", null, \"Kubernetes will continue to provide support for Klog-specific flags for the foreseeable future. However, it is recommended that developers and system administrators begin transitioning their applications to the OpenTelemetry framework. This will ensure that their applications are using the industry-standard solution for logging and instrumentation.\"), mdx(\"p\", null, \"Overall, the deprecation of Klog-specific flags is a positive step forward for Kubernetes. It will ensure that Kubernetes users have access to the most reliable and comprehensive solution for logging and instrumentation. It will also help ensure that Kubernetes is using the industry-standard solution and will provide developers and system administrators with a more reliable and consistent experience when instrumenting their applications.\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Structured logging in Kubernetes with Klog","subtitle":"Deprecating Klog flags in Kubernetes 1.26","date":"December 5th, 2022","author":"Lee Calcote","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAACsElEQVQ4y5WUWU8TURiG+RfGW40m/gYw3kqMicEtkJioxCvjhRC9IRqlCESoUfGCKLKXpbKY4MJY3EggYBu9QCiCkrazddqhp9CFOst5TWfBplKok7w5Z87ynHe+b85XAuuhlG63ml6ccvZQq09L8mH/+9gg+7Ukd8KeY3wJPHsTQxdD0OshGJmOG+rxEHROEmO8kyEQZKWwQ91ytyZk8GgsAlZKIiCmsPAzjgZXGE2DYSyubSAgJMFHUvB4Y+j1xIw9mr4TUDeB/mAaw5/MhYqi4np7BNeeiIZudkQAqhlzrJRBnwXUdwMuh9LonzIXzi0lcOoOD2Y+gomZCCru8vi2mjTmVtit4oBLgTS6GXPhciBhQJoHw3D0h3HGwWONN4Gr3F5AK4YhKQOPL26lSsfsQgxX2wTjk71+YoyZsS7S4bw/BYcriofjxNSYDKdbRKtbRNtLGa0jBO7pTfiDqe3Q7AhUNRPYPCRjf1UI5XUsDlezONfA4nQ9h5O3OVQ2sjhwkcWxGzxmv29g6CMpDNQshw9GZRy6zKHRJaCqiUd9n4DmQREdr8JwugWcuMXjeJ2AucX47sBch/sqQzh/j8dZB2ckoqKeR3kdj2qngCNXWByt5TGzsAfQjuHc0iYcfSKcLyS0uiXcHzbVktOOTsewEkpi4D0pLsuMN25l819RXcFvRYXvRxLP364X8R8G0+h5Z90UFVA1GOHIro8nVFxokVBWK6CslsOHrxvFXT33Z7JjZYmSDEprOBy8xMI1JWdRyG7btTj84rfweFyGuK4gKCkISQoCkgJxXYV3OYnSGhYDBky3Yf+UL0r/HkGprtPJL4Q+fR2l3YxMuyZNZfvtE1Hq8REKaNSsr9aefIf5Vds8UC8g5Dqz6uh2YTYd2qfYrZ5NZkHRfGfUZmSBfwDCm8IDFXo9BQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/1fa301d3f987db757b54e34bfe04b9a5/db189/kubernetes-logs.png","srcSet":"/static/1fa301d3f987db757b54e34bfe04b9a5/f054e/kubernetes-logs.png 750w,\n/static/1fa301d3f987db757b54e34bfe04b9a5/db189/kubernetes-logs.png 900w","sizes":"100vw"},"sources":[{"srcSet":"/static/1fa301d3f987db757b54e34bfe04b9a5/4f03f/kubernetes-logs.webp 750w,\n/static/1fa301d3f987db757b54e34bfe04b9a5/3987a/kubernetes-logs.webp 900w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}},"extension":"png","publicURL":"/static/1fa301d3f987db757b54e34bfe04b9a5/kubernetes-logs.png"}},"fields":{"slug":"/blog/kubernetes/structured-logging-in-kubernetes-with-klog"}},{"id":"fbda537a-afd2-57b2-b44d-784c1df43d3c","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Multi-Cluster Kubernetes Management with Meshery\",\n  \"subtitle\": \"Wrangling your services one cluster at-a-time\",\n  \"date\": \"2022-07-28 08:00:00 -0630\",\n  \"author\": \"Ashish Tiwari\",\n  \"description\": \"Manage all of your Kubernetes clusters with the cloud native management plane, Meshery. Learn how Meshery makes connecting, discovering, and configuring multiple clusters a breeze.\",\n  \"thumbnail\": \"./multi-cluster-kubernetes-management-with-meshery.png\",\n  \"darkthumbnail\": \"./multi-cluster-kubernetes-management-with-meshery.png\",\n  \"category\": \"Meshery\",\n  \"tags\": [\"Meshery\", \"Multi-cluster\", \"Kubernetes\"],\n  \"type\": \"Blog\",\n  \"featured\": true,\n  \"published\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(BlogWrapper, {\n    mdxType: \"BlogWrapper\"\n  }, mdx(\"div\", {\n    className: \"intro\"\n  }, mdx(\"p\", null, \"From multi-mesh to now multi-cluster, \", mdx(Link, {\n    to: \"/meshery\",\n    mdxType: \"Link\"\n  }, \"Meshery\"), \" is continuously expanding its capability to give developers, operators, and security engineers more control over their infrastructure. In this post, we'll take a look behind the scenes at how each component in Meshery's architecture plays a role in the management of many Kubernetes clusters.\")), mdx(\"h2\", null, \"Philosophy behind Meshery's multi-cluster management approach\"), mdx(\"p\", null, \"While designing Meshery for the world of many service meshes, and many Kubernetes clusters, much care has been taken to ensure that Meshery is an \", mdx(\"a\", {\n    href: \"https://docs.meshery.io/extensibility\"\n  }, \"extensible management platform\"), \", ready for handling new types of infrastructure and new use cases rapidly through its plugin model. Under the hood, \", mdx(\"a\", {\n    href: \"https://docs.meshery.io\"\n  }, \"Meshery Server\"), \" acts as a delegator of operations by figuring out which Meshery Adapter registered its capability against the given operation. The operation is then sent to that given component (like one of Meshery\\u2019s service mesh adapters,e.g. Istio adapter) via a gRPC call. \", mdx(\"img\", {\n    src: CoreArch,\n    alt: \"deploy modal\",\n    className: \"image-right\"\n  }), \" When the operation involves a Kubernetes cluster(s), the kubeconfig(s) is sent as a parameter to the RPCs. It is then the job of the handling adapter to respect that and perform the operation across the passed clusters from kubeconfigs as needed. The operations not requiring a kubeconfig are managed through the same RPC, with the only difference being that the handling component would ignore the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubeconfigs\"), \" field altogether making the system work not just for Kubernetes, but for other cloud native use cases. This approach of reusing the same RPC for different types of requests is pretty common and sometimes debatable with the other approach of being strict with the RPCs. This is what makes Meshery completely pluggable and extensible.\"), mdx(\"h2\", null, \"Using multi cluster with Meshery\"), mdx(\"p\", null, \"From a client's perspective, there are two uses of the multi context feature in general. While deploying a \", mdx(Link, {\n    to: \"/meshmap\",\n    mdxType: \"Link\"\n  }, \"MeshMap\"), \" design or performing any other operation on their cluster(s), selecting any number of Kubernetes contexts will allow them to uniformly and parallely perform the operation across the clusters. And while visualizing the state of their cluster(s), the same context switcher will allow them to filter across the clusters whose view they want to see.\"), mdx(\"p\", null, \"All cluster specific operations are now applied over a number of clusters uniformly. So if you have 10 clusters to manage and 8 of those start with the exact same set of pods, deployments, service mesh, etc then \", mdx(Link, {\n    to: \"/meshery\",\n    mdxType: \"Link\"\n  }, \"Meshery\"), \" can help you to apply these operations quickly and easily.\"), mdx(\"p\", null, \"It is as simple as selecting the specific cluster(s) from the Kubernetes context switcher in the navbar, and then applying whatever operation you wanted to, whether that be deploying a sample app, a service mesh, or a \", mdx(Link, {\n    to: \"/meshmap\",\n    mdxType: \"Link\"\n  }, \"MeshMap\"), \" design.\"), mdx(\"p\", {\n    align: \"center\"\n  }, mdx(\"img\", {\n    src: Switcher,\n    alt: \"context switcher\",\n    className: \"image-center-shadow\"\n  })), mdx(\"p\", null, \"Just before applying the operation, you will be prompted with a confirmation modal which will provide the information about which cluster(s) that operation will be performed against. As the User interface improves, this same modal will also convey more useful information about the operation they are going to perform.\"), mdx(\"p\", {\n    align: \"center\"\n  }, mdx(\"img\", {\n    src: Deploy,\n    alt: \"deploy modal\",\n    className: \"image-center-shadow\"\n  })), mdx(\"br\", null), mdx(\"h3\", null, \"Using MeshMap visualizer\"), mdx(\"p\", null, \"You can switch between views of your cluster in visualizer mode while using \", mdx(Link, {\n    to: \"/meshmap\",\n    mdxType: \"Link\"\n  }, \"MeshMap\"), \".\"), mdx(\"p\", {\n    align: \"center\"\n  }, mdx(\"img\", {\n    src: Cluster2,\n    alt: \"visualizer showing data of context1\",\n    className: \"slides-right\"\n  })), mdx(\"p\", {\n    align: \"center\"\n  }, mdx(\"img\", {\n    src: Cluster1,\n    alt: \"visualizer showing data of context2\",\n    className: \"slides-left\"\n  })), mdx(\"h3\", null, \"Managing Meshery on multiple clusters\"), mdx(\"p\", null, \"Users can perform cluster related operations from the settings page like adding more clusters, removing data from existing clusters and removing existing clusters.\"), mdx(\"img\", {\n    src: Settings,\n    alt: \"Settings page\",\n    className: \"slides-right\"\n  }), mdx(\"p\", null, \"Meshery also deploys Meshery operator across the cluster it\\u2019s about to manage. This operator manages the lifecycle of a Meshery broker and MeshSync. MeshSync pumps the blood into Meshery\\u2019s core, in other words, it is responsible for watching all different types of resources by establishing a watch stream over each of them. MeshSync then pumps that data into the NATS server, of which Meshery server itself is a client. From there, Meshery server gets all the relevant data related to activities in the cluster.\"), mdx(\"p\", null, \"By default, \", mdx(Link, {\n    to: \"/meshery\",\n    mdxType: \"Link\"\n  }, \"Meshery\"), \" wants to be as much aware about your infrastructure as possible to provide value so it deploys its operator across each detected cluster. But you can fine tune this configuration by going over each one of them from the table as shown.\"), mdx(\"img\", {\n    src: Cluster,\n    alt: \"Kubernetes multi-cluster management with Meshery\",\n    className: \"image-center-shadow\"\n  }), mdx(\"p\", null, \"If you disconnect your cluster and do not want to persist the data from that cluster then you can perform a fine-grained deletion by deleting all MeshSync data (which are the Kubernetes objects) for that specific cluster.\"), mdx(\"img\", {\n    src: Flush,\n    alt: \"flushing MeshSync data\",\n    className: \"image-center-shadow\"\n  }), mdx(\"h2\", null, \"Future of multi-cluster\"), mdx(\"p\", null, \"Meshery as an extension point to your infrastructure provides out-of-the-box value by adding components which can be Kubernetes specific, service mesh specific or custom components to add new functionality. We can now add multi-cluster specific components to provide more abstraction. This model can be used along with Meshery\\u2019s multi-mesh capabilities to give an overall multi-mesh multi-cluster experience to the user. For instance, your Istio service mesh spanning across multiple clusters can be abstracted and managed by Meshery using custom components such as VirtualGateway and VirtualDestinationRules. In this case, Meshery\\u2019s Istio adapter will handle the logic of converting a VirtualGateway into gateways across the clusters. This abstraction provides high value by powering the service mesh to span across the clusters while the Ops team can configure the mesh with minimal effort.\"), mdx(\"p\", null, \"Just like the example above, many such Meshery extension points are in Meshery to add logic into and add useful functionality. And as more of such extension points are added, Meshery will continue to give more and more power to your cloud native infrastructure.\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Multi-Cluster Kubernetes Management with Meshery","subtitle":"Wrangling your services one cluster at-a-time","date":"July 28th, 2022","author":"Ashish Tiwari","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAACjUlEQVQoz2WS7UtTYRjG9/9ENnSGmk63Nnc8nuM258tqmGkOlCzCJFPIZiUloQSaoFBKSW1YshTUadgoItQPe9HNN2SbnolT1G3Kvl7x3Mr60IeL5+Y5nOv5Xfd9y5SlRig5PbJ4PQxNzXA4J/HY1o2Ma2pYW9tgbmiCSjQhureHeDxOSiaTdCYSCarZeXR0hOPjY8h6B4egrLoJeakeN+ob4ZyaRvvrPshLyqAWypGt5sAelaJRMvH7/fB6vQgGgwgEAqTNzU0yY6YysboGCksNFJwIodKCl/2DqGtrR7aWh0ZfiVdvBvDo6XPs7ErY39+Hx+PB8vIyGa+srGBpaYkeODg4OCfM0/C4YjChqrEZM7MuTE3PYOGHGy0dnXjQ9QKz3xfgWnDj5OQEkUgEgWAQ6+vrpHA4TISsZt9YApmq1IhLvIiuoWHMz83D/mUCE85JjNod0NXU4e3we9h6ehGO7CARjxMNI/P5fOnILH66h5miEZe1PDq6e+D++QvOySm4XHMY+TCG3GIBmUXFKBTKqYeMkvVrY2ODojMjVm9tbf0zvPvEhgKdSAPo6x+E3fkN78bHYaxtgFypQT5XBp3JnB7K6ekpUqkUxWUxWc3u0oajnxwoEk3IUHOQCwaU1FuRpzfB1HQP1k4bsgQjtMZq7EoSzs7OEFxbw+LiItExytXVVYRCIaKnKTOzilorBkY/QrTchqJIh0LeAMdXJ9y//0BjqYWqrIIIk4kEJEmiiIyOGW1vbxNt2lCh4mC+04iRsc8QzbeQqxNJDfcforXzGfKKBSKMRs8Xm/1Iy3yx2EzsnsWlyAW8ATlaAQo1R0PIL9GTrl7naalzLgxD4QgODw9pF/9TLIbYhf4CmGqHkKpZuT4AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/322f708c880bf8749f760d3c3cad9a64/afa5c/multi-cluster-kubernetes-management-with-meshery.png","srcSet":"/static/322f708c880bf8749f760d3c3cad9a64/0dee1/multi-cluster-kubernetes-management-with-meshery.png 750w,\n/static/322f708c880bf8749f760d3c3cad9a64/8beaa/multi-cluster-kubernetes-management-with-meshery.png 1080w,\n/static/322f708c880bf8749f760d3c3cad9a64/d079a/multi-cluster-kubernetes-management-with-meshery.png 1366w,\n/static/322f708c880bf8749f760d3c3cad9a64/afa5c/multi-cluster-kubernetes-management-with-meshery.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/322f708c880bf8749f760d3c3cad9a64/a66aa/multi-cluster-kubernetes-management-with-meshery.webp 750w,\n/static/322f708c880bf8749f760d3c3cad9a64/65dd5/multi-cluster-kubernetes-management-with-meshery.webp 1080w,\n/static/322f708c880bf8749f760d3c3cad9a64/4fad6/multi-cluster-kubernetes-management-with-meshery.webp 1366w,\n/static/322f708c880bf8749f760d3c3cad9a64/c512e/multi-cluster-kubernetes-management-with-meshery.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}},"extension":"png","publicURL":"/static/322f708c880bf8749f760d3c3cad9a64/multi-cluster-kubernetes-management-with-meshery.png"}},"fields":{"slug":"/blog/meshery/multi-cluster-kubernetes-management-with-meshery"}},{"id":"0bf099ea-9608-5c18-9882-81c42e07ea75","body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"How to deploy Meshery on AKS\",\n  \"date\": \"2022-07-21 08:00:00 -0630\",\n  \"author\": \"Srinivas Karnati\",\n  \"category\": \"Meshery\",\n  \"description\": \"How to deploy Meshery on Azure Kubernetes service(AKS).\",\n  \"tags\": [\"Meshery\", \"Kubernetes\"],\n  \"thumbnail\": \"./Meshery-on-AKS.png\",\n  \"darkthumbnail\": \"./Meshery-on-AKS.png\",\n  \"type\": \"Blog\",\n  \"published\": true,\n  \"resource\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(BlogWrapper, {\n    mdxType: \"BlogWrapper\"\n  }, mdx(\"div\", {\n    className: \"intro\"\n  }, mdx(\"p\", null, mdx(\"a\", {\n    href: \"https://meshery.io/\"\n  }, \"Meshery\"), \"'s goal is to make the operation of cloud native infrastructure and the service mesh layer of cloud simplified. Originally created by Layer5, Meshery is an open source project with hundreds of contributors world-wide and is actively maintained by engineers from Red Hat, VMware, Intel, Layer5 and others.\")), mdx(\"h2\", null, \"Setup and run Meshery on AKS\"), mdx(\"p\", null, \"The following instructions expects you to have an active Azure subscription, and Azure CLI installed on your system. \"), mdx(\"h3\", null, \" Spin up the AKS Cluster\"), mdx(\"p\", null, \"Create the resource group (a logical group where all our resources will be deployed). The following command creates  a resource group named MesheryGroup in \", mdx(\"code\", null, \"southindia\"), \" location. \"), mdx(\"pre\", null, mdx(\"code\", {\n    className: \"language-bash\"\n  }, \"az group create --name MesheryGroup --location southindia\")), mdx(\"p\", null, \"Create AKS cluster using \", mdx(\"code\", null, \"az aks create\"), \". The following command creates aks cluster with a single node. \"), mdx(\"pre\", null, mdx(\"code\", {\n    className: \"language-bash\"\n  }, \"az aks create --resource-group MesheryGroup --name MesheryAKS --node-count 1 --generate-ssh-keys\")), mdx(\"p\", null, \"After a few minutes, the command completes and returns a JSON formatted information about the cluster.\"), mdx(\"p\", null, \"You can connect with your cluster by using \", mdx(\"code\", null, \"az aks get-credentials\"), \" ,  which basically downloads credentials and configure the Kubernetes CLI. \"), mdx(\"pre\", null, mdx(\"code\", null, \"az aks get-credentials --resource-group MesheryGroup --name MesheryAKS\")), mdx(\"p\", null, \"Verify the connection to your cluster using the \", mdx(\"code\", null, \"kubectl get command\"), \". \"), mdx(\"pre\", null, mdx(\"code\", null, \"$kubectl get nodes\")), mdx(\"h3\", null, \"Install Meshery into your AKS cluster\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"helm repo add meshery https://meshery.io/charts/\\n\\nhelm install meshery meshery/meshery --namespace meshery --create-namespace\\n\\n\")), mdx(\"p\", null, \"Meshery server supports customizing authentication flow callback URL, which can be configured in the following way.\"), mdx(\"pre\", null, mdx(\"code\", null, \"helm install meshery meshery/meshery --namespace meshery --set env.MESHERY_SERVER_CALLBACK_URL=https://custom-host --create-namespace\")), mdx(\"p\", null, \"Port forward to Meshery UI\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"export POD_NAME=$(kubectl get pods --namespace meshery -l \\\"app.kubernetes.io/name=meshery,app.kubernetes.io/instance=meshery\\\" -o jsonpath=\\\"{.items[0].metadata.name}\\\")\\n\\n$ kubectl --namespace meshery port-forward $POD_NAME 9081:8080\\n\\n\")), mdx(\"p\", null, \"Meshery should now be running in your AKS cluster and the Meshery UI should be accessible at the specified endpoint you\\u2019ve exposed to. Navigate to the meshery service endpoint to log into Meshery.\"), mdx(\"div\", null, mdx(\"img\", {\n    src: mesheryui,\n    className: \"image-center\",\n    alt: \"Meshery UI Dashboard\"\n  })), mdx(\"p\", null, \"From here, your Meshery deployment on AKS is ready to use. In order to login to Meshery, authenticate with your chosen provider from the list.\"), mdx(\"p\", null, \"There are different ways to configure a Meshery on AKS. Join the \", mdx(\"a\", {\n    href: \"https://layer5.io/community\"\n  }, \"community\"), \" and share your deployment\\u2019s configuration on the \", mdx(\"a\", {\n    href: \"https://discuss.layer5.io/\"\n  }, \" discussion forum \"), \"today! \")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"How to deploy Meshery on AKS","subtitle":null,"date":"July 21st, 2022","author":"Srinivas Karnati","thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAA7EAAAOxAGVKw4bAAABqUlEQVQoz6WS3UsbURDF97ViVNJGGhHf2se+tImW7KY0Hya7a8wWi6KVRus2NVpjqyikRSJIE0TSEKsUChEUBAX1yf/vV+50V6QIgj4MM3eGOTPnzNVCf2oE9+t0nbfo295Az46im6PEzDz6HUwLHu7waO8H3SdNHjc20TP3BOy62CX8s0qwvc3AxjrxlI1uOVI0rDzGDU2GV48JGy+f/beE1ru3xYPjX/ScNXnpjKEP54imLKJJk0jSFD+YshhK25IfTNu8SGQl9sEUUMxS5qAFTxs8rZTloWdyGLbDlFtiurhIobQk/m3B5c30LBMfPjH2fo7i8iqTbkk2jHmA8fQIrxImmkoa6RHRztdNgcx/XeNjeRW3vIK7tMLk3DwzC8uMzxb5vFbhXXFBpFH9SqZnhRn6qxU0/doUX5do0hJakURWvKKpLCL0bZ6/zghl0XA4R9/WdwLnu/S0d9CuwBSwJ7LhCe/b/8cQbzvEExZPvn0hcNQk1K7z8HcN7bZvcP2Sfny1RCZH6KAuPyTcrBI4aNwOeOMQn5GVZ6BWoeOwReflPuHWJn8BuGF+tgE2sKcAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/4f9edd5fbd1229cce133102a7fa8d084/a6312/Meshery-on-AKS.png","srcSet":"/static/4f9edd5fbd1229cce133102a7fa8d084/e7dcc/Meshery-on-AKS.png 750w,\n/static/4f9edd5fbd1229cce133102a7fa8d084/50eb2/Meshery-on-AKS.png 1080w,\n/static/4f9edd5fbd1229cce133102a7fa8d084/a6312/Meshery-on-AKS.png 1200w","sizes":"100vw"},"sources":[{"srcSet":"/static/4f9edd5fbd1229cce133102a7fa8d084/ee7ce/Meshery-on-AKS.webp 750w,\n/static/4f9edd5fbd1229cce133102a7fa8d084/819dc/Meshery-on-AKS.webp 1080w,\n/static/4f9edd5fbd1229cce133102a7fa8d084/f9756/Meshery-on-AKS.webp 1200w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}},"extension":"png","publicURL":"/static/4f9edd5fbd1229cce133102a7fa8d084/Meshery-on-AKS.png"}},"fields":{"slug":"/blog/meshery/how-to-deploy-meshery-on-aks"}}]}},"pageContext":{"tag":"Kubernetes"}},"staticQueryHashes":["1485533831","2449327605","3205812809","4047814605"]}